{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Common Task 1 â€“ Variational Autoencoder on Jet Images (DeepFalcon GSoC 2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
    "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
    "!pip install -q torch-geometric\n",
    "!pip install -q h5py imageio seaborn open3d tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JetDataset(Dataset):\n",
    "    def __init__(self, npz_path):\n",
    "        data = np.load(npz_path)\n",
    "        self.ecal = data['ecal']\n",
    "        self.hcal = data['hcal']\n",
    "        self.track = data['track']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ecal)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.stack([self.ecal[idx], self.hcal[idx], self.track[idx]], axis=0)\n",
    "        return torch.tensor(image, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/content/jet_images_3ch.npz'\n",
    "dataset = JetDataset(data_path)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(64*16*16, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(64*16*16, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(latent_dim, 64*16*16)\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 3, 4, 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.fc(z).view(-1, 64, 16, 16)\n",
    "        return self.deconv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim=32):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(latent_dim)\n",
    "        self.decoder = Decoder(latent_dim)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(x, x_recon, mu, logvar):\n",
    "    recon_loss = F.mse_loss(x_recon, x, reduction='sum')\n",
    "    kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(latent_dim=32).cuda()\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    vae.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        batch = batch.cuda()\n",
    "        recon, mu, logvar = vae(batch)\n",
    "        loss = vae_loss(batch, recon, mu, logvar)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(dataset):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    test_batch = next(iter(dataloader)).cuda()\n",
    "    recon_batch, _, _ = vae(test_batch)\n",
    "\n",
    "    def show_images(original, reconstructed, n=8):\n",
    "        original = original[:n].cpu()\n",
    "        reconstructed = reconstructed[:n].cpu()\n",
    "        fig, axs = plt.subplots(2, n, figsize=(n * 2, 4))\n",
    "        for i in range(n):\n",
    "            axs[0, i].imshow(np.transpose(original[i], (1, 2, 0)))\n",
    "            axs[0, i].set_title(\"Original\")\n",
    "            axs[0, i].axis('off')\n",
    "            axs[1, i].imshow(np.transpose(reconstructed[i], (1, 2, 0)))\n",
    "            axs[1, i].set_title(\"Reconstructed\")\n",
    "            axs[1, i].axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    show_images(test_batch, recon_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vae.state_dict(), \"vae_jet.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
